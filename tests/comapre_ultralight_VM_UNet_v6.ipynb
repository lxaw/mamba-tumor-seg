{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PP just in the bottle neck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import os\n",
    "\n",
    "from dice_loss import DiceLoss\n",
    "import torch.optim as optim\n",
    "from brain_mri_dataset import BrainMRIDatasetBuilder,BrainMRIDataset\n",
    "\n",
    "from transforms import BrainMRITransforms\n",
    "\n",
    "from BCEDiceLoss import BceDiceLoss\n",
    "\n",
    "from calculate_iou import calculate_iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch\n",
    "batch_size = 2\n",
    "\n",
    "learning_rate = 0.0003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../datasets/lgg-mri-segmentation/kaggle_3m\"\n",
    "\n",
    "builder = BrainMRIDatasetBuilder(data_dir)\n",
    "df = builder.create_df()\n",
    "train_df, val_df, test_df = builder.split_df(df)\n",
    "\n",
    "transform_ = BrainMRITransforms()\n",
    "\n",
    "train_data = BrainMRIDataset(train_df, transform = transform_ ,  mask_transform= transform_)\n",
    "val_data = BrainMRIDataset(val_df, transform = transform_ ,  mask_transform= transform_)\n",
    "test_data = BrainMRIDataset(test_df, transform = transform_ ,  mask_transform= transform_)\n",
    "\n",
    "train_dataloader = DataLoader(train_data, batch_size = batch_size , shuffle = True)\n",
    "val_dataloader = DataLoader(val_data, batch_size = batch_size , shuffle = True)\n",
    "test_dataloader = DataLoader(test_data, batch_size = batch_size , shuffle = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 3143, validation size: 393, test size: 393\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train size: {train_df.shape[0]}, validation size: {val_df.shape[0]}, test size: {test_df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from timm.models.layers import trunc_normal_\n",
    "import math\n",
    "from mamba_ssm import Mamba\n",
    "\n",
    "\n",
    "from pyramidal_pooling import PyramidalPoolingModule\n",
    "\n",
    "\n",
    "class PVMLayer(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, d_state = 16, d_conv = 4, expand = 2, pp=False):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.norm = nn.LayerNorm(input_dim)\n",
    "        self.mamba = Mamba(\n",
    "                d_model=input_dim//8, # Model dimension d_model\n",
    "                d_state=d_state,  # SSM state expansion factor\n",
    "                d_conv=d_conv,    # Local convolution width\n",
    "                expand=expand,    # Block expansion factor\n",
    "        )\n",
    "        self.proj = nn.Linear(input_dim, output_dim)\n",
    "        self.skip_scale= nn.Parameter(torch.ones(1))\n",
    "        self.pp = pp\n",
    "        \n",
    "        if self.pp == True:\n",
    "            self.ppm = PyramidalPoolingModule(input_channels=input_dim,\n",
    "                                          pool_sizes=(1,2,3,6),\n",
    "                                          output_channels=[input_dim//8, input_dim//4, input_dim//2, input_dim//8]) \n",
    "    \n",
    "    def forward(self, x):\n",
    "        if x.dtype == torch.float16:\n",
    "            x = x.type(torch.float32)\n",
    "\n",
    "        if self.pp == True:\n",
    "            ## Pyramidal Pooling\n",
    "            x = self.ppm(x)\n",
    "\n",
    "        B, C = x.shape[:2]\n",
    "        assert C == self.input_dim\n",
    "        n_tokens = x.shape[2:].numel()\n",
    "        img_dims = x.shape[2:]\n",
    "        x_flat = x.reshape(B, C, n_tokens).transpose(-1, -2)\n",
    "        x_norm = self.norm(x_flat)\n",
    "\n",
    "        x1, x2, x3, x4, x5, x6, x7, x8 = torch.chunk(x_norm, 8, dim=2)\n",
    "        x_mamba1 = self.mamba(x1) + self.skip_scale * x1\n",
    "        x_mamba2 = self.mamba(x2) + self.skip_scale * x2\n",
    "        x_mamba3 = self.mamba(x3) + self.skip_scale * x3\n",
    "        x_mamba4 = self.mamba(x4) + self.skip_scale * x4\n",
    "        x_mamba5 = self.mamba(x5) + self.skip_scale * x5\n",
    "        x_mamba6 = self.mamba(x6) + self.skip_scale * x6\n",
    "        x_mamba7 = self.mamba(x7) + self.skip_scale * x7\n",
    "        x_mamba8 = self.mamba(x8) + self.skip_scale * x8\n",
    "        x_mamba = torch.cat([x_mamba1, x_mamba2,x_mamba3,x_mamba4,x_mamba5,x_mamba6,x_mamba7,x_mamba8], dim=2)\n",
    "\n",
    "        x_mamba = self.norm(x_mamba)\n",
    "        x_mamba = self.proj(x_mamba)\n",
    "        out = x_mamba.transpose(-1, -2).reshape(B, self.output_dim, *img_dims)\n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "class Channel_Att_Bridge(nn.Module):\n",
    "    def __init__(self, c_list, split_att='fc'):\n",
    "        super().__init__()\n",
    "        c_list_sum = sum(c_list) - c_list[-1]\n",
    "        self.split_att = split_att\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.get_all_att = nn.Conv1d(1, 1, kernel_size=3, padding=1, bias=False)\n",
    "        self.att1 = nn.Linear(c_list_sum, c_list[0]) if split_att == 'fc' else nn.Conv1d(c_list_sum, c_list[0], 1)\n",
    "        self.att2 = nn.Linear(c_list_sum, c_list[1]) if split_att == 'fc' else nn.Conv1d(c_list_sum, c_list[1], 1)\n",
    "        self.att3 = nn.Linear(c_list_sum, c_list[2]) if split_att == 'fc' else nn.Conv1d(c_list_sum, c_list[2], 1)\n",
    "        self.att4 = nn.Linear(c_list_sum, c_list[3]) if split_att == 'fc' else nn.Conv1d(c_list_sum, c_list[3], 1)\n",
    "        self.att5 = nn.Linear(c_list_sum, c_list[4]) if split_att == 'fc' else nn.Conv1d(c_list_sum, c_list[4], 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, t1, t2, t3, t4, t5):\n",
    "        att = torch.cat((self.avgpool(t1), \n",
    "                         self.avgpool(t2), \n",
    "                         self.avgpool(t3), \n",
    "                         self.avgpool(t4), \n",
    "                         self.avgpool(t5)), dim=1)\n",
    "        att = self.get_all_att(att.squeeze(-1).transpose(-1, -2))\n",
    "        if self.split_att != 'fc':\n",
    "            att = att.transpose(-1, -2)\n",
    "        att1 = self.sigmoid(self.att1(att))\n",
    "        att2 = self.sigmoid(self.att2(att))\n",
    "        att3 = self.sigmoid(self.att3(att))\n",
    "        att4 = self.sigmoid(self.att4(att))\n",
    "        att5 = self.sigmoid(self.att5(att))\n",
    "        if self.split_att == 'fc':\n",
    "            att1 = att1.transpose(-1, -2).unsqueeze(-1).expand_as(t1)\n",
    "            att2 = att2.transpose(-1, -2).unsqueeze(-1).expand_as(t2)\n",
    "            att3 = att3.transpose(-1, -2).unsqueeze(-1).expand_as(t3)\n",
    "            att4 = att4.transpose(-1, -2).unsqueeze(-1).expand_as(t4)\n",
    "            att5 = att5.transpose(-1, -2).unsqueeze(-1).expand_as(t5)\n",
    "        else:\n",
    "            att1 = att1.unsqueeze(-1).expand_as(t1)\n",
    "            att2 = att2.unsqueeze(-1).expand_as(t2)\n",
    "            att3 = att3.unsqueeze(-1).expand_as(t3)\n",
    "            att4 = att4.unsqueeze(-1).expand_as(t4)\n",
    "            att5 = att5.unsqueeze(-1).expand_as(t5)\n",
    "            \n",
    "        return att1, att2, att3, att4, att5\n",
    "    \n",
    "    \n",
    "class Spatial_Att_Bridge(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.shared_conv2d = nn.Sequential(nn.Conv2d(2, 1, 7, stride=1, padding=9, dilation=3),\n",
    "                                          nn.Sigmoid())\n",
    "    \n",
    "    def forward(self, t1, t2, t3, t4, t5):\n",
    "        t_list = [t1, t2, t3, t4, t5]\n",
    "        att_list = []\n",
    "        for t in t_list:\n",
    "            avg_out = torch.mean(t, dim=1, keepdim=True)\n",
    "            max_out, _ = torch.max(t, dim=1, keepdim=True)\n",
    "            att = torch.cat([avg_out, max_out], dim=1)\n",
    "            att = self.shared_conv2d(att)\n",
    "            att_list.append(att)\n",
    "        return att_list[0], att_list[1], att_list[2], att_list[3], att_list[4]\n",
    "\n",
    "    \n",
    "class SC_Att_Bridge(nn.Module):\n",
    "    def __init__(self, c_list, split_att='fc'):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.catt = Channel_Att_Bridge(c_list, split_att=split_att)\n",
    "        self.satt = Spatial_Att_Bridge()\n",
    "        \n",
    "    def forward(self, t1, t2, t3, t4, t5):\n",
    "        r1, r2, r3, r4, r5 = t1, t2, t3, t4, t5\n",
    "\n",
    "        satt1, satt2, satt3, satt4, satt5 = self.satt(t1, t2, t3, t4, t5)\n",
    "        t1, t2, t3, t4, t5 = satt1 * t1, satt2 * t2, satt3 * t3, satt4 * t4, satt5 * t5\n",
    "\n",
    "        r1_, r2_, r3_, r4_, r5_ = t1, t2, t3, t4, t5\n",
    "        t1, t2, t3, t4, t5 = t1 + r1, t2 + r2, t3 + r3, t4 + r4, t5 + r5\n",
    "\n",
    "        catt1, catt2, catt3, catt4, catt5 = self.catt(t1, t2, t3, t4, t5)\n",
    "        t1, t2, t3, t4, t5 = catt1 * t1, catt2 * t2, catt3 * t3, catt4 * t4, catt5 * t5\n",
    "\n",
    "        return t1 + r1_, t2 + r2_, t3 + r3_, t4 + r4_, t5 + r5_\n",
    "    \n",
    "\n",
    "class UltraLight_VM_UNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_classes=1, input_channels=3, c_list=[8,16,24,32,48,64],\n",
    "                split_att='fc', bridge=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.bridge = bridge\n",
    "        \n",
    "        self.encoder1 = nn.Sequential(\n",
    "            nn.Conv2d(input_channels, c_list[0], 3, stride=1, padding=1),\n",
    "        )\n",
    "        self.encoder2 =nn.Sequential(\n",
    "            nn.Conv2d(c_list[0], c_list[1], 3, stride=1, padding=1),\n",
    "        ) \n",
    "        self.encoder3 = nn.Sequential(\n",
    "            nn.Conv2d(c_list[1], c_list[2], 3, stride=1, padding=1),\n",
    "        )\n",
    "        self.encoder4 = nn.Sequential(\n",
    "            PVMLayer(input_dim=c_list[2], output_dim=c_list[3])\n",
    "        )\n",
    "        self.encoder5 = nn.Sequential(\n",
    "            PVMLayer(input_dim=c_list[3], output_dim=c_list[4])\n",
    "        )\n",
    "        self.encoder6 = nn.Sequential(\n",
    "            PVMLayer(input_dim=c_list[4], output_dim=c_list[5], pp=True)\n",
    "        )\n",
    "\n",
    "        if bridge: \n",
    "            self.scab = SC_Att_Bridge(c_list, split_att)\n",
    "            print('SC_Att_Bridge was used')\n",
    "        \n",
    "        self.decoder1 = nn.Sequential(\n",
    "            PVMLayer(input_dim=c_list[5], output_dim=c_list[4])\n",
    "        ) \n",
    "        self.decoder2 = nn.Sequential(\n",
    "            PVMLayer(input_dim=c_list[4], output_dim=c_list[3])\n",
    "        ) \n",
    "        self.decoder3 = nn.Sequential(\n",
    "            PVMLayer(input_dim=c_list[3], output_dim=c_list[2])\n",
    "        )  \n",
    "        self.decoder4 = nn.Sequential(\n",
    "            nn.Conv2d(c_list[2], c_list[1], 3, stride=1, padding=1),\n",
    "        )  \n",
    "        self.decoder5 = nn.Sequential(\n",
    "            nn.Conv2d(c_list[1], c_list[0], 3, stride=1, padding=1),\n",
    "        )  \n",
    "        self.ebn1 = nn.GroupNorm(4, c_list[0])\n",
    "        self.ebn2 = nn.GroupNorm(4, c_list[1])\n",
    "        self.ebn3 = nn.GroupNorm(4, c_list[2])\n",
    "        self.ebn4 = nn.GroupNorm(4, c_list[3])\n",
    "        self.ebn5 = nn.GroupNorm(4, c_list[4])\n",
    "        self.dbn1 = nn.GroupNorm(4, c_list[4])\n",
    "        self.dbn2 = nn.GroupNorm(4, c_list[3])\n",
    "        self.dbn3 = nn.GroupNorm(4, c_list[2])\n",
    "        self.dbn4 = nn.GroupNorm(4, c_list[1])\n",
    "        self.dbn5 = nn.GroupNorm(4, c_list[0])\n",
    "\n",
    "        self.final = nn.Conv2d(c_list[0], num_classes, kernel_size=1)\n",
    "\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            trunc_normal_(m.weight, std=.02)\n",
    "            if isinstance(m, nn.Linear) and m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        elif isinstance(m, nn.Conv1d):\n",
    "                n = m.kernel_size[0] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "        elif isinstance(m, nn.Conv2d):\n",
    "            fan_out = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "            fan_out //= m.groups\n",
    "            m.weight.data.normal_(0, math.sqrt(2.0 / fan_out))\n",
    "            if m.bias is not None:\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        out = F.gelu(F.max_pool2d(self.ebn1(self.encoder1(x)),2,2))\n",
    "        t1 = out # b, c0, H/2, W/2\n",
    "\n",
    "        out = F.gelu(F.max_pool2d(self.ebn2(self.encoder2(out)),2,2))\n",
    "        t2 = out # b, c1, H/4, W/4 \n",
    "\n",
    "        out = F.gelu(F.max_pool2d(self.ebn3(self.encoder3(out)),2,2))\n",
    "        t3 = out # b, c2, H/8, W/8\n",
    "        \n",
    "        out = F.gelu(F.max_pool2d(self.ebn4(self.encoder4(out)),2,2))\n",
    "        t4 = out # b, c3, H/16, W/16\n",
    "        \n",
    "        out = F.gelu(F.max_pool2d(self.ebn5(self.encoder5(out)),2,2))\n",
    "        t5 = out # b, c4, H/32, W/32\n",
    "\n",
    "        if self.bridge: t1, t2, t3, t4, t5 = self.scab(t1, t2, t3, t4, t5)\n",
    "        \n",
    "        out = F.gelu(self.encoder6(out)) # b, c5, H/32, W/32\n",
    "        \n",
    "        out5 = F.gelu(self.dbn1(self.decoder1(out))) # b, c4, H/32, W/32\n",
    "        out5 = torch.add(out5, t5) # b, c4, H/32, W/32\n",
    "        \n",
    "        out4 = F.gelu(F.interpolate(self.dbn2(self.decoder2(out5)),scale_factor=(2,2),mode ='bilinear',align_corners=True)) # b, c3, H/16, W/16\n",
    "        out4 = torch.add(out4, t4) # b, c3, H/16, W/16\n",
    "        \n",
    "        out3 = F.gelu(F.interpolate(self.dbn3(self.decoder3(out4)),scale_factor=(2,2),mode ='bilinear',align_corners=True)) # b, c2, H/8, W/8\n",
    "        out3 = torch.add(out3, t3) # b, c2, H/8, W/8\n",
    "        \n",
    "        out2 = F.gelu(F.interpolate(self.dbn4(self.decoder4(out3)),scale_factor=(2,2),mode ='bilinear',align_corners=True)) # b, c1, H/4, W/4\n",
    "        out2 = torch.add(out2, t2) # b, c1, H/4, W/4 \n",
    "        \n",
    "        out1 = F.gelu(F.interpolate(self.dbn5(self.decoder5(out2)),scale_factor=(2,2),mode ='bilinear',align_corners=True)) # b, c0, H/2, W/2\n",
    "        out1 = torch.add(out1, t1) # b, c0, H/2, W/2\n",
    "        \n",
    "        out0 = F.interpolate(self.final(out1),scale_factor=(2,2),mode ='bilinear',align_corners=True) # b, num_class, H, W\n",
    "        \n",
    "        return torch.sigmoid(out0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SC_Att_Bridge was used\n"
     ]
    }
   ],
   "source": [
    "model = nn.DataParallel(UltraLight_VM_UNet(\n",
    "    num_classes=1,\n",
    "    input_channels=3,\n",
    "    # c_list=[8,16,24,32,48,64],\n",
    "    c_list=[16,32,64,128,256,512],\n",
    "    split_att='fc',\n",
    "    bridge=True\n",
    ")).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 769677\n",
      "Trainable parameters: 769677\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f'Total parameters: {total_params}')\n",
    "print(f'Trainable parameters: {trainable_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = BceDiceLoss()\n",
    "optimizer = optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = \"../checkpoints/modified_ultralightmunet_v6_checkpoints/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/100, Train Loss: 0.4609, Val Loss: 0.4679\n",
      "Epoch: 2/100, Train Loss: 0.3521, Val Loss: 0.2586\n",
      "Epoch: 3/100, Train Loss: 0.3291, Val Loss: 0.3118\n",
      "Epoch: 4/100, Train Loss: 0.2974, Val Loss: 0.2525\n",
      "Epoch: 5/100, Train Loss: 0.3119, Val Loss: 0.3463\n",
      "Epoch: 6/100, Train Loss: 0.3249, Val Loss: 0.2434\n",
      "Epoch: 7/100, Train Loss: 0.2733, Val Loss: 0.2200\n",
      "Epoch: 8/100, Train Loss: 0.2531, Val Loss: 0.1892\n",
      "Epoch: 9/100, Train Loss: 0.2665, Val Loss: 0.2542\n",
      "Epoch: 10/100, Train Loss: 0.2676, Val Loss: 0.2532\n",
      "Epoch: 11/100, Train Loss: 0.2390, Val Loss: 0.2660\n",
      "Epoch: 12/100, Train Loss: 0.2587, Val Loss: 0.1811\n",
      "Epoch: 13/100, Train Loss: 0.2232, Val Loss: 0.1915\n",
      "Epoch: 14/100, Train Loss: 0.2284, Val Loss: 0.2264\n",
      "Epoch: 15/100, Train Loss: 0.2409, Val Loss: 0.1916\n",
      "Epoch: 16/100, Train Loss: 0.2270, Val Loss: 0.1767\n",
      "Epoch: 17/100, Train Loss: 0.2077, Val Loss: 0.1694\n",
      "Epoch: 18/100, Train Loss: 0.2770, Val Loss: 0.2353\n",
      "Epoch: 19/100, Train Loss: 0.2547, Val Loss: 0.1919\n",
      "Epoch: 20/100, Train Loss: 0.1940, Val Loss: 0.1642\n",
      "Epoch: 21/100, Train Loss: 0.1952, Val Loss: 0.1928\n",
      "Epoch: 22/100, Train Loss: 0.1872, Val Loss: 0.2068\n",
      "Epoch: 23/100, Train Loss: 0.1841, Val Loss: 0.2109\n",
      "Epoch: 24/100, Train Loss: 0.1683, Val Loss: 0.1387\n",
      "Epoch: 25/100, Train Loss: 0.1889, Val Loss: 0.1713\n",
      "Epoch: 26/100, Train Loss: 0.1969, Val Loss: 0.1595\n",
      "Epoch: 27/100, Train Loss: 0.1728, Val Loss: 0.1490\n",
      "Epoch: 28/100, Train Loss: 0.1604, Val Loss: 0.1394\n",
      "Epoch: 29/100, Train Loss: 0.1562, Val Loss: 0.1430\n",
      "Epoch: 30/100, Train Loss: 0.1608, Val Loss: 0.1597\n",
      "Epoch: 31/100, Train Loss: 0.1548, Val Loss: 0.1543\n",
      "Epoch: 32/100, Train Loss: 0.1634, Val Loss: 0.1441\n",
      "Epoch: 33/100, Train Loss: 0.1842, Val Loss: 0.1533\n",
      "Epoch: 34/100, Train Loss: 0.1495, Val Loss: 0.1624\n",
      "Epoch: 35/100, Train Loss: 0.1399, Val Loss: 0.1314\n",
      "Epoch: 36/100, Train Loss: 0.1424, Val Loss: 0.1445\n",
      "Epoch: 37/100, Train Loss: 0.1359, Val Loss: 0.1315\n",
      "Epoch: 38/100, Train Loss: 0.1382, Val Loss: 0.1698\n",
      "Epoch: 39/100, Train Loss: 0.1342, Val Loss: 0.1342\n",
      "Epoch: 40/100, Train Loss: 0.1258, Val Loss: 0.1364\n",
      "Epoch: 41/100, Train Loss: 0.1325, Val Loss: 0.1342\n",
      "Epoch: 42/100, Train Loss: 0.1208, Val Loss: 0.1148\n",
      "Epoch: 43/100, Train Loss: 0.1328, Val Loss: 0.1652\n",
      "Epoch: 44/100, Train Loss: 0.1238, Val Loss: 0.1706\n",
      "Epoch: 45/100, Train Loss: 0.1129, Val Loss: 0.1192\n",
      "Epoch: 46/100, Train Loss: 0.1218, Val Loss: 0.1142\n",
      "Epoch: 47/100, Train Loss: 0.1209, Val Loss: 0.1202\n",
      "Epoch: 48/100, Train Loss: 0.1201, Val Loss: 0.1161\n",
      "Epoch: 49/100, Train Loss: 0.1379, Val Loss: 0.1227\n",
      "Epoch: 50/100, Train Loss: 0.1094, Val Loss: 0.1083\n",
      "Epoch: 51/100, Train Loss: 0.1190, Val Loss: 0.1345\n",
      "Epoch: 52/100, Train Loss: 0.1163, Val Loss: 0.2155\n",
      "Epoch: 53/100, Train Loss: 0.1807, Val Loss: 0.1187\n",
      "Epoch: 54/100, Train Loss: 0.1270, Val Loss: 0.1492\n",
      "Epoch: 55/100, Train Loss: 0.1149, Val Loss: 0.1280\n",
      "Epoch: 56/100, Train Loss: 0.1076, Val Loss: 0.1279\n",
      "Epoch: 57/100, Train Loss: 0.1168, Val Loss: 0.1216\n",
      "Epoch: 58/100, Train Loss: 0.1202, Val Loss: 0.1173\n",
      "Epoch: 59/100, Train Loss: 0.1109, Val Loss: 0.1185\n",
      "Epoch: 60/100, Train Loss: 0.1085, Val Loss: 0.1313\n",
      "Epoch: 61/100, Train Loss: 0.0959, Val Loss: 0.1160\n",
      "Epoch: 62/100, Train Loss: 0.1204, Val Loss: 0.1174\n",
      "Epoch: 63/100, Train Loss: 0.1032, Val Loss: 0.1294\n",
      "Epoch: 64/100, Train Loss: 0.1037, Val Loss: 0.0984\n",
      "Epoch: 65/100, Train Loss: 0.0984, Val Loss: 0.1161\n",
      "Epoch: 66/100, Train Loss: 0.1026, Val Loss: 0.1903\n",
      "Epoch: 67/100, Train Loss: 0.0994, Val Loss: 0.1001\n",
      "Epoch: 68/100, Train Loss: 0.0980, Val Loss: 0.1064\n",
      "Epoch: 69/100, Train Loss: 0.1005, Val Loss: 0.1021\n",
      "Epoch: 70/100, Train Loss: 0.1085, Val Loss: 0.1202\n",
      "Epoch: 71/100, Train Loss: 0.0958, Val Loss: 0.1005\n",
      "Epoch: 72/100, Train Loss: 0.0974, Val Loss: 0.1216\n",
      "Epoch: 73/100, Train Loss: 0.1041, Val Loss: 0.1046\n",
      "Epoch: 74/100, Train Loss: 0.0932, Val Loss: 0.1358\n",
      "Epoch: 75/100, Train Loss: 0.1040, Val Loss: 0.1061\n",
      "Epoch: 76/100, Train Loss: 0.0932, Val Loss: 0.1279\n",
      "Epoch: 77/100, Train Loss: 0.0965, Val Loss: 0.0914\n",
      "Epoch: 78/100, Train Loss: 0.0915, Val Loss: 0.0944\n",
      "Epoch: 79/100, Train Loss: 0.0958, Val Loss: 0.0884\n",
      "Epoch: 80/100, Train Loss: 0.0885, Val Loss: 0.1301\n",
      "Epoch: 81/100, Train Loss: 0.1030, Val Loss: 0.0954\n",
      "Epoch: 82/100, Train Loss: 0.0923, Val Loss: 0.1101\n",
      "Epoch: 83/100, Train Loss: 0.0878, Val Loss: 0.0996\n",
      "Epoch: 84/100, Train Loss: 0.1071, Val Loss: 0.0967\n",
      "Epoch: 85/100, Train Loss: 0.0858, Val Loss: 0.0907\n",
      "Epoch: 86/100, Train Loss: 0.0810, Val Loss: 0.0929\n",
      "Epoch: 87/100, Train Loss: 0.0903, Val Loss: 0.0896\n",
      "Epoch: 88/100, Train Loss: 0.1012, Val Loss: 0.0869\n",
      "Epoch: 89/100, Train Loss: 0.0864, Val Loss: 0.0989\n",
      "Epoch: 90/100, Train Loss: 0.0832, Val Loss: 0.0982\n",
      "Epoch: 91/100, Train Loss: 0.0800, Val Loss: 0.0908\n",
      "Epoch: 92/100, Train Loss: 0.0951, Val Loss: 0.0914\n",
      "Epoch: 93/100, Train Loss: 0.0840, Val Loss: 0.1063\n",
      "Epoch: 94/100, Train Loss: 0.0823, Val Loss: 0.1102\n",
      "Epoch: 95/100, Train Loss: 0.0805, Val Loss: 0.1170\n",
      "Epoch: 96/100, Train Loss: 0.0858, Val Loss: 0.1223\n",
      "Epoch: 97/100, Train Loss: 0.0884, Val Loss: 0.1004\n",
      "Epoch: 98/100, Train Loss: 0.0780, Val Loss: 0.0894\n",
      "Epoch: 99/100, Train Loss: 0.0835, Val Loss: 0.1019\n",
      "Epoch: 100/100, Train Loss: 0.0774, Val Loss: 0.0903\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "\n",
    "train_loss = []\n",
    "val_loss = []\n",
    "trainIOU = []\n",
    "valIOU = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    total_train_loss = 0\n",
    "    total_val_loss = 0\n",
    "\n",
    "    # Training mode\n",
    "    model.train()\n",
    "    total_train_iou = 0\n",
    "\n",
    "    for imgs, labels in train_dataloader:\n",
    "        imgs, labels = imgs.to(device).float(), labels.to(device).float()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        pred = model(imgs)\n",
    "\n",
    "        loss = criterion(pred, labels)\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    train_loss.append(total_train_loss / len(train_dataloader))\n",
    "\n",
    "    # Validation mode \n",
    "    model.eval()\n",
    "    total_val_iou = 0\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in val_dataloader:\n",
    "            imgs, labels = imgs.to(device).float(), labels.to(device).float()\n",
    "            \n",
    "            pred = model(imgs)\n",
    "\n",
    "            loss = criterion(pred, labels)\n",
    "            total_val_loss += loss.item()\n",
    "\n",
    "    total_val_loss = total_val_loss / len(val_dataloader)\n",
    "    val_loss.append(total_val_loss)\n",
    "        \n",
    "    # Print\n",
    "    print('Epoch: {}/{}, Train Loss: {:.4f}, Val Loss: {:.4f}'.format(epoch + 1, epochs, train_loss[-1], total_val_loss))\n",
    "\n",
    "    # Save checkpoint\n",
    "    checkpoint_path = os.path.join(checkpoint_dir, f'modified_ultralightmunet_v6_checkpoint_epoch_{epoch+1}.pt')\n",
    "    torch.save(model.state_dict(), checkpoint_path)\n",
    "\n",
    "# Assuming your model is named 'model' and you want to save its state_dict\n",
    "model_state_dict = model.state_dict()\n",
    "\n",
    "# Specify the file path where you want to save the weights\n",
    "file_path = 'modified_ultralightmunet_v6_weights.pth'\n",
    "\n",
    "# Save the model state_dict to the specified file\n",
    "torch.save(model_state_dict, file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "umamba",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
