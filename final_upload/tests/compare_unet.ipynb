{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import os\n",
    "\n",
    "from dice_loss import DiceLoss\n",
    "import torch.optim as optim\n",
    "from brain_mri_dataset import BrainMRIDatasetBuilder,BrainMRIDataset\n",
    "\n",
    "from transforms import BrainMRITransforms\n",
    "\n",
    "from calculate_iou import calculate_iou\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch\n",
    "batch_size = 64\n",
    "\n",
    "learning_rate = 0.0003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../datasets/lgg-mri-segmentation/kaggle_3m\"\n",
    "\n",
    "builder = BrainMRIDatasetBuilder(data_dir)\n",
    "df = builder.create_df()\n",
    "train_df, val_df, test_df = builder.split_df(df)\n",
    "\n",
    "transform_ = BrainMRITransforms()\n",
    "\n",
    "train_data = BrainMRIDataset(train_df, transform = transform_ ,  mask_transform= transform_)\n",
    "val_data = BrainMRIDataset(val_df, transform = transform_ ,  mask_transform= transform_)\n",
    "test_data = BrainMRIDataset(test_df, transform = transform_ ,  mask_transform= transform_)\n",
    "\n",
    "train_dataloader = DataLoader(train_data, batch_size = batch_size , shuffle = True)\n",
    "val_dataloader = DataLoader(val_data, batch_size = batch_size , shuffle = True)\n",
    "test_dataloader = DataLoader(test_data, batch_size = batch_size , shuffle = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "images_paths    ../datasets/lgg-mri-segmentation/kaggle_3m/TCG...\n",
       "masks_paths     ../datasets/lgg-mri-segmentation/kaggle_3m/TCG...\n",
       "Name: 653, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\t (3143, 2) \n",
      "Val\t (393, 2) \n",
      "Test\t (393, 2)\n"
     ]
    }
   ],
   "source": [
    "print('Train\\t', train_df.shape, '\\nVal\\t', val_df.shape, '\\nTest\\t', test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    # def __init__(self, threshold=0.5):\n",
    "    def __init__(self):\n",
    "        super(UNet, self).__init__()\n",
    "        # self.threshold = threshold\n",
    "\n",
    "        # Encoder\n",
    "        self.encoder1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.encoder2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.encoder3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.encoder4 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # Bottleneck\n",
    "        self.bottleneck = nn.Sequential(\n",
    "            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "        # Decoder\n",
    "        self.upconv4 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n",
    "        self.decoder4 = nn.Sequential(\n",
    "            nn.Conv2d(512, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.upconv3 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
    "        self.decoder3 = nn.Sequential(\n",
    "            nn.Conv2d(256, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.upconv2 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
    "        self.decoder2 = nn.Sequential(\n",
    "            nn.Conv2d(128, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.upconv1 = nn.ConvTranspose2d(64, 32, kernel_size=2, stride=2)\n",
    "        self.decoder1 = nn.Sequential(\n",
    "            nn.Conv2d(64, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        # Final conv layer\n",
    "        self.conv = nn.Conv2d(32, 1, kernel_size=1)  # Output 1 channel for the mask\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        encoder1 = self.encoder1(x)\n",
    "        encoder2 = self.encoder2(self.pool1(encoder1))\n",
    "        encoder3 = self.encoder3(self.pool2(encoder2))\n",
    "        encoder4 = self.encoder4(self.pool3(encoder3))\n",
    "\n",
    "        # Bottleneck\n",
    "        bottleneck = self.bottleneck(self.pool4(encoder4))\n",
    "\n",
    "        # Decoder & Connections\n",
    "        x = self.upconv4(bottleneck)\n",
    "        x = torch.cat([x, encoder4], dim=1)\n",
    "        x = self.decoder4(x)\n",
    "\n",
    "        x = self.upconv3(x)\n",
    "        x = torch.cat([x, encoder3], dim=1)\n",
    "        x = self.decoder3(x)\n",
    "\n",
    "        x = self.upconv2(x)\n",
    "        x = torch.cat([x, encoder2], dim=1)\n",
    "        x = self.decoder2(x)\n",
    "\n",
    "        x = self.upconv1(x)\n",
    "        x = torch.cat([x, encoder1], dim=1)\n",
    "        x = self.decoder1(x)\n",
    "\n",
    "        x = self.conv(x)\n",
    "\n",
    "        # # Thresholding\n",
    "        # if self.training:\n",
    "        #     # During training, apply sigmoid activation\n",
    "        #     x = torch.sigmoid(x)\n",
    "        # else:\n",
    "        #     # During inference, apply thresholding\n",
    "        #     x = torch.where(x >= self.threshold, torch.tensor(1.0).to(x.device), torch.tensor(0.0).to(x.device))\n",
    "\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet()\n",
    "model = nn.DataParallel(model)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 7765985\n",
      "Trainable parameters: 7765985\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f'Total parameters: {total_params}')\n",
    "print(f'Trainable parameters: {trainable_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = DiceLoss()\n",
    "optimizer = optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = \"../checkpoints/unet_checkpoints/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/jccrews/miniconda3/envs/umamba/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/100, Train Loss: 0.9603, Val Loss: 0.9581\n",
      "Epoch: 2/100, Train Loss: 0.9516, Val Loss: 0.9518\n",
      "Epoch: 3/100, Train Loss: 0.9462, Val Loss: 0.9417\n",
      "Epoch: 4/100, Train Loss: 0.9401, Val Loss: 0.9346\n",
      "Epoch: 5/100, Train Loss: 0.9316, Val Loss: 0.9322\n",
      "Epoch: 6/100, Train Loss: 0.9199, Val Loss: 0.9304\n",
      "Epoch: 7/100, Train Loss: 0.9021, Val Loss: 0.8812\n",
      "Epoch: 8/100, Train Loss: 0.8811, Val Loss: 0.8544\n",
      "Epoch: 9/100, Train Loss: 0.8435, Val Loss: 0.8308\n",
      "Epoch: 10/100, Train Loss: 0.7909, Val Loss: 0.7906\n",
      "Epoch: 11/100, Train Loss: 0.7347, Val Loss: 0.7657\n",
      "Epoch: 12/100, Train Loss: 0.6672, Val Loss: 0.6180\n",
      "Epoch: 13/100, Train Loss: 0.5604, Val Loss: 0.4970\n",
      "Epoch: 14/100, Train Loss: 0.4656, Val Loss: 0.4472\n",
      "Epoch: 15/100, Train Loss: 0.3899, Val Loss: 0.3567\n",
      "Epoch: 16/100, Train Loss: 0.3380, Val Loss: 0.3092\n",
      "Epoch: 17/100, Train Loss: 0.2941, Val Loss: 0.2869\n",
      "Epoch: 18/100, Train Loss: 0.2701, Val Loss: 0.2699\n",
      "Epoch: 19/100, Train Loss: 0.2310, Val Loss: 0.2098\n",
      "Epoch: 20/100, Train Loss: 0.2180, Val Loss: 0.2010\n",
      "Epoch: 21/100, Train Loss: 0.1845, Val Loss: 0.1840\n",
      "Epoch: 22/100, Train Loss: 0.1740, Val Loss: 0.2854\n",
      "Epoch: 23/100, Train Loss: 0.2287, Val Loss: 0.2134\n",
      "Epoch: 24/100, Train Loss: 0.1901, Val Loss: 0.2061\n",
      "Epoch: 25/100, Train Loss: 0.1848, Val Loss: 0.1612\n",
      "Epoch: 26/100, Train Loss: 0.1682, Val Loss: 0.1965\n",
      "Epoch: 27/100, Train Loss: 0.1617, Val Loss: 0.1536\n",
      "Epoch: 28/100, Train Loss: 0.1664, Val Loss: 0.1423\n",
      "Epoch: 29/100, Train Loss: 0.1326, Val Loss: 0.1539\n",
      "Epoch: 30/100, Train Loss: 0.1357, Val Loss: 0.1366\n",
      "Epoch: 31/100, Train Loss: 0.1259, Val Loss: 0.1335\n",
      "Epoch: 32/100, Train Loss: 0.1336, Val Loss: 0.1352\n",
      "Epoch: 33/100, Train Loss: 0.1219, Val Loss: 0.1262\n",
      "Epoch: 34/100, Train Loss: 0.1136, Val Loss: 0.1339\n",
      "Epoch: 35/100, Train Loss: 0.1075, Val Loss: 0.1151\n",
      "Epoch: 36/100, Train Loss: 0.1181, Val Loss: 0.3299\n",
      "Epoch: 37/100, Train Loss: 0.2891, Val Loss: 0.3275\n",
      "Epoch: 38/100, Train Loss: 0.2029, Val Loss: 0.1522\n",
      "Epoch: 39/100, Train Loss: 0.1461, Val Loss: 0.1589\n",
      "Epoch: 40/100, Train Loss: 0.1394, Val Loss: 0.1143\n",
      "Epoch: 41/100, Train Loss: 0.1206, Val Loss: 0.1175\n",
      "Epoch: 42/100, Train Loss: 0.1164, Val Loss: 0.1222\n",
      "Epoch: 43/100, Train Loss: 0.1147, Val Loss: 0.1247\n",
      "Epoch: 44/100, Train Loss: 0.1024, Val Loss: 0.1194\n",
      "Epoch: 45/100, Train Loss: 0.1025, Val Loss: 0.1131\n",
      "Epoch: 46/100, Train Loss: 0.1298, Val Loss: 0.1183\n",
      "Epoch: 47/100, Train Loss: 0.1082, Val Loss: 0.1257\n",
      "Epoch: 48/100, Train Loss: 0.1039, Val Loss: 0.1205\n",
      "Epoch: 49/100, Train Loss: 0.1083, Val Loss: 0.1127\n",
      "Epoch: 50/100, Train Loss: 0.1016, Val Loss: 0.1125\n",
      "Epoch: 51/100, Train Loss: 0.0961, Val Loss: 0.1062\n",
      "Epoch: 52/100, Train Loss: 0.0898, Val Loss: 0.1183\n",
      "Epoch: 53/100, Train Loss: 0.0903, Val Loss: 0.1119\n",
      "Epoch: 54/100, Train Loss: 0.1044, Val Loss: 0.1079\n",
      "Epoch: 55/100, Train Loss: 0.1112, Val Loss: 0.1154\n",
      "Epoch: 56/100, Train Loss: 0.0957, Val Loss: 0.1116\n",
      "Epoch: 57/100, Train Loss: 0.0905, Val Loss: 0.1194\n",
      "Epoch: 58/100, Train Loss: 0.0976, Val Loss: 0.1617\n",
      "Epoch: 59/100, Train Loss: 0.0938, Val Loss: 0.0999\n",
      "Epoch: 60/100, Train Loss: 0.0889, Val Loss: 0.1001\n",
      "Epoch: 61/100, Train Loss: 0.0877, Val Loss: 0.0941\n",
      "Epoch: 62/100, Train Loss: 0.0911, Val Loss: 0.1054\n",
      "Epoch: 63/100, Train Loss: 0.0928, Val Loss: 0.1247\n",
      "Epoch: 64/100, Train Loss: 0.0906, Val Loss: 0.1070\n",
      "Epoch: 65/100, Train Loss: 0.0899, Val Loss: 0.1008\n",
      "Epoch: 66/100, Train Loss: 0.1258, Val Loss: 0.1143\n",
      "Epoch: 67/100, Train Loss: 0.1224, Val Loss: 0.1048\n",
      "Epoch: 68/100, Train Loss: 0.0947, Val Loss: 0.1046\n",
      "Epoch: 69/100, Train Loss: 0.0910, Val Loss: 0.1162\n",
      "Epoch: 70/100, Train Loss: 0.0848, Val Loss: 0.0964\n",
      "Epoch: 71/100, Train Loss: 0.0863, Val Loss: 0.2048\n",
      "Epoch: 72/100, Train Loss: 0.0857, Val Loss: 0.1059\n",
      "Epoch: 73/100, Train Loss: 0.0864, Val Loss: 0.1593\n",
      "Epoch: 74/100, Train Loss: 0.1528, Val Loss: 0.1283\n",
      "Epoch: 75/100, Train Loss: 0.1151, Val Loss: 0.1135\n",
      "Epoch: 76/100, Train Loss: 0.1070, Val Loss: 0.1079\n",
      "Epoch: 77/100, Train Loss: 0.1000, Val Loss: 0.1007\n",
      "Epoch: 78/100, Train Loss: 0.0917, Val Loss: 0.1045\n",
      "Epoch: 79/100, Train Loss: 0.0906, Val Loss: 0.2512\n",
      "Epoch: 80/100, Train Loss: 0.1861, Val Loss: 0.1551\n",
      "Epoch: 81/100, Train Loss: 0.1425, Val Loss: 0.1327\n",
      "Epoch: 82/100, Train Loss: 0.1061, Val Loss: 0.1035\n",
      "Epoch: 83/100, Train Loss: 0.0923, Val Loss: 0.0952\n",
      "Epoch: 84/100, Train Loss: 0.0852, Val Loss: 0.1761\n",
      "Epoch: 85/100, Train Loss: 0.0894, Val Loss: 0.0965\n",
      "Epoch: 86/100, Train Loss: 0.0898, Val Loss: 0.1034\n",
      "Epoch: 87/100, Train Loss: 0.0831, Val Loss: 0.0959\n",
      "Epoch: 88/100, Train Loss: 0.0812, Val Loss: 0.1015\n",
      "Epoch: 89/100, Train Loss: 0.0824, Val Loss: 0.1031\n",
      "Epoch: 90/100, Train Loss: 0.0824, Val Loss: 0.1019\n",
      "Epoch: 91/100, Train Loss: 0.0977, Val Loss: 0.0970\n",
      "Epoch: 92/100, Train Loss: 0.0809, Val Loss: 0.1150\n",
      "Epoch: 93/100, Train Loss: 0.0770, Val Loss: 0.0956\n",
      "Epoch: 94/100, Train Loss: 0.0883, Val Loss: 0.1010\n",
      "Epoch: 95/100, Train Loss: 0.0798, Val Loss: 0.1058\n",
      "Epoch: 96/100, Train Loss: 0.0766, Val Loss: 0.1028\n",
      "Epoch: 97/100, Train Loss: 0.0812, Val Loss: 0.1024\n",
      "Epoch: 98/100, Train Loss: 0.0862, Val Loss: 0.0991\n",
      "Epoch: 99/100, Train Loss: 0.0843, Val Loss: 0.0983\n",
      "Epoch: 100/100, Train Loss: 0.0794, Val Loss: 0.1027\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "\n",
    "train_loss = []\n",
    "val_loss = []\n",
    "trainIOU = []\n",
    "valIOU = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    total_train_loss = 0\n",
    "    total_val_loss = 0\n",
    "\n",
    "    # Training mode\n",
    "    model.train()\n",
    "    total_train_iou = 0\n",
    "\n",
    "    for imgs, labels in train_dataloader:\n",
    "        imgs, labels = imgs.to(device).float(), labels.to(device).float()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        pred = model(imgs)\n",
    "\n",
    "        loss = criterion(pred, labels)\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "        iou = calculate_iou(pred, labels)\n",
    "        total_train_iou += iou.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    train_iou = total_train_iou / len(train_dataloader)\n",
    "    trainIOU.append(train_iou)\n",
    "\n",
    "    train_loss.append(total_train_loss / len(train_dataloader))\n",
    "\n",
    "    # Validation mode \n",
    "    model.eval()\n",
    "    total_val_iou = 0\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in val_dataloader:\n",
    "            imgs, labels = imgs.to(device).float(), labels.to(device).float()\n",
    "            \n",
    "            pred = model(imgs)\n",
    "            \n",
    "            loss = criterion(pred, labels)\n",
    "            total_val_loss += loss.item()\n",
    "\n",
    "            iou = calculate_iou(pred, labels)\n",
    "            total_val_iou += iou.item()\n",
    "\n",
    "    val_iou = total_val_iou / len(val_dataloader)\n",
    "    valIOU.append(val_iou)\n",
    "    total_val_loss = total_val_loss / len(val_dataloader)\n",
    "    val_loss.append(total_val_loss)\n",
    "        \n",
    "    # Print\n",
    "    print('Epoch: {}/{}, Train Loss: {:.4f}, Val Loss: {:.4f}'.format(epoch + 1, epochs, train_loss[-1], total_val_loss))\n",
    "\n",
    "    # Save checkpoint\n",
    "    checkpoint_path = os.path.join(checkpoint_dir, f'unet_checkpoint_epoch_{epoch+1}.pt')\n",
    "    torch.save(model.state_dict(), checkpoint_path)\n",
    "\n",
    "# Assuming your model is named 'model' and you want to save its state_dict\n",
    "model_state_dict = model.state_dict()\n",
    "\n",
    "# Specify the file path where you want to save the weights\n",
    "file_path = 'unet_weights.pth'\n",
    "\n",
    "# Save the model state_dict to the specified file\n",
    "torch.save(model_state_dict, file_path)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "umamba",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
